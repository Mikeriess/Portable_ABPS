{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72dabd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mpmath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4f6c165",
   "metadata": {},
   "outputs": [],
   "source": [
    "from algorithms.alg1_timeline_simulation import Run_simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2600433",
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment.DoE import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48dcdcc",
   "metadata": {},
   "source": [
    "# Generate design table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3b0a1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   F_priority_scheme  days  F_number_of_agents  Repetition  Done  RUN\n",
      "0               FCFS  10.0                 3.0         0.0     0    1\n",
      "1                NPS  10.0                 3.0         0.0     0    2\n",
      "2               FCFS  10.0                 3.0         1.0     0    3\n",
      "3                NPS  10.0                 3.0         1.0     0    4\n",
      "4               FCFS  10.0                 3.0         2.0     0    5\n",
      "5                NPS  10.0                 3.0         2.0     0    6\n",
      "6               FCFS  10.0                 3.0         3.0     0    7\n",
      "7                NPS  10.0                 3.0         3.0     0    8\n",
      "8               FCFS  10.0                 3.0         4.0     0    9\n",
      "9                NPS  10.0                 3.0         4.0     0   10\n",
      "10              FCFS  10.0                 3.0         5.0     0   11\n",
      "11               NPS  10.0                 3.0         5.0     0   12\n",
      "12              FCFS  10.0                 3.0         6.0     0   13\n",
      "13               NPS  10.0                 3.0         6.0     0   14\n",
      "14              FCFS  10.0                 3.0         7.0     0   15\n",
      "15               NPS  10.0                 3.0         7.0     0   16\n",
      "16              FCFS  10.0                 3.0         8.0     0   17\n",
      "17               NPS  10.0                 3.0         8.0     0   18\n",
      "18              FCFS  10.0                 3.0         9.0     0   19\n",
      "19               NPS  10.0                 3.0         9.0     0   20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mike\\desktop\\Portable_ABPS\\experiment\\DoE.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[variable].loc[run] = value\n"
     ]
    }
   ],
   "source": [
    "#Simple setup for testing purposes:\n",
    "run_settings = {'F_priority_scheme':[\"FCFS\",\"NPS\"],#\n",
    "            \"days\":[10],\n",
    "            'F_number_of_agents':[3],\n",
    "            'Repetition':list(range(0,10))}                #\n",
    "\n",
    "# Generate a full factorial:\n",
    "df=build_full_fact(run_settings)  \n",
    "\n",
    "# Constants affecting the experiments:\n",
    "df[\"Done\"] = 0 #Flag if the final model has been trained\n",
    "df[\"RUN\"] = df.index + 1\n",
    "\n",
    "# fix integer coding of string factor levels\n",
    "variables = [\"F_priority_scheme\"]\n",
    "df = fix_label_values(df, run_settings, variables)\n",
    "df.drop(\"Name_fix\",axis=1, inplace=True)\n",
    "print(df)\n",
    "\n",
    "# Save the settings to a file\n",
    "#np.save(\"results/experiment_settings.npy\", run_settings) \n",
    "\n",
    "#store the new experimental design\n",
    "df.to_csv(\"results/experiments.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "061bdef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = df\n",
    "experiments.index = experiments.RUN.values\n",
    "experiment_list = experiments.RUN.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1162b0b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "301663a8",
   "metadata": {},
   "source": [
    "# Run some experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7cc5f68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================================\n",
      "Starting experiment:  1\n",
      "2018-07-01 00:00:00\n",
      "day 0 start\n",
      "day 1 start\n",
      "day 2 start\n",
      "day 3 start\n",
      "day 4 start\n",
      "day 5 start\n",
      "day 6 start\n",
      "day 7 start\n",
      "day 8 start\n",
      "day 9 start\n",
      "generating eventlog...\n",
      "================================================================================================\n",
      "Starting experiment:  2\n",
      "2018-07-01 00:00:00\n",
      "day 0 start\n",
      "day 1 start\n",
      "day 2 start\n",
      "day 3 start\n",
      "day 4 start\n",
      "day 5 start\n",
      "day 6 start\n",
      "day 7 start\n",
      "day 8 start\n",
      "day 9 start\n",
      "generating eventlog...\n",
      "================================================================================================\n",
      "Starting experiment:  3\n",
      "2018-07-01 00:00:00\n",
      "day 0 start\n",
      "day 1 start\n",
      "day 2 start\n",
      "day 3 start\n",
      "day 4 start\n",
      "day 5 start\n",
      "day 6 start\n",
      "day 7 start\n",
      "day 8 start\n",
      "day 9 start\n",
      "generating eventlog...\n",
      "================================================================================================\n",
      "Starting experiment:  4\n",
      "2018-07-01 00:00:00\n",
      "day 0 start\n",
      "day 1 start\n",
      "day 2 start\n",
      "day 3 start\n",
      "day 4 start\n",
      "day 5 start\n",
      "day 6 start\n",
      "day 7 start\n",
      "day 8 start\n",
      "day 9 start\n",
      "generating eventlog...\n",
      "================================================================================================\n",
      "Starting experiment:  5\n",
      "2018-07-01 00:00:00\n",
      "day 0 start\n",
      "day 1 start\n",
      "day 2 start\n",
      "day 3 start\n",
      "day 4 start\n",
      "day 5 start\n",
      "day 6 start\n",
      "day 7 start\n",
      "day 8 start\n",
      "day 9 start\n",
      "generating eventlog...\n",
      "================================================================================================\n",
      "Starting experiment:  6\n",
      "2018-07-01 00:00:00\n",
      "day 0 start\n",
      "day 1 start\n",
      "day 2 start\n",
      "day 3 start\n",
      "day 4 start\n",
      "day 5 start\n",
      "day 6 start\n",
      "day 7 start\n",
      "day 8 start\n",
      "day 9 start\n",
      "generating eventlog...\n",
      "================================================================================================\n",
      "Starting experiment:  7\n",
      "2018-07-01 00:00:00\n",
      "day 0 start\n",
      "day 1 start\n",
      "day 2 start\n",
      "day 3 start\n",
      "day 4 start\n",
      "day 5 start\n",
      "day 6 start\n",
      "day 7 start\n",
      "day 8 start\n",
      "day 9 start\n",
      "generating eventlog...\n",
      "================================================================================================\n",
      "Starting experiment:  8\n",
      "2018-07-01 00:00:00\n",
      "day 0 start\n",
      "day 1 start\n",
      "day 2 start\n",
      "day 3 start\n",
      "day 4 start\n",
      "day 5 start\n",
      "day 6 start\n",
      "day 7 start\n",
      "day 8 start\n",
      "day 9 start\n",
      "generating eventlog...\n",
      "================================================================================================\n",
      "Starting experiment:  9\n",
      "2018-07-01 00:00:00\n",
      "day 0 start\n",
      "day 1 start\n",
      "day 2 start\n",
      "day 3 start\n",
      "day 4 start\n",
      "day 5 start\n",
      "day 6 start\n",
      "day 7 start\n",
      "day 8 start\n",
      "day 9 start\n",
      "generating eventlog...\n",
      "================================================================================================\n",
      "Starting experiment:  10\n",
      "2018-07-01 00:00:00\n",
      "day 0 start\n",
      "day 1 start\n",
      "day 2 start\n",
      "day 3 start\n",
      "day 4 start\n",
      "day 5 start\n",
      "day 6 start\n",
      "day 7 start\n",
      "day 8 start\n",
      "day 9 start\n",
      "generating eventlog...\n",
      "================================================================================================\n",
      "Starting experiment:  11\n",
      "2018-07-01 00:00:00\n",
      "day 0 start\n",
      "day 1 start\n",
      "day 2 start\n",
      "day 3 start\n",
      "day 4 start\n",
      "day 5 start\n",
      "day 6 start\n",
      "day 7 start\n",
      "day 8 start\n",
      "day 9 start\n",
      "generating eventlog...\n",
      "================================================================================================\n",
      "Starting experiment:  12\n",
      "2018-07-01 00:00:00\n",
      "day 0 start\n",
      "day 1 start\n",
      "day 2 start\n",
      "day 3 start\n",
      "day 4 start\n",
      "day 5 start\n",
      "day 6 start\n",
      "day 7 start\n",
      "day 8 start\n",
      "day 9 start\n",
      "generating eventlog...\n",
      "================================================================================================\n",
      "Starting experiment:  13\n",
      "2018-07-01 00:00:00\n",
      "day 0 start\n",
      "day 1 start\n",
      "day 2 start\n",
      "day 3 start\n",
      "day 4 start\n",
      "day 5 start\n",
      "day 6 start\n",
      "day 7 start\n",
      "day 8 start\n",
      "day 9 start\n",
      "generating eventlog...\n",
      "================================================================================================\n",
      "Starting experiment:  14\n",
      "2018-07-01 00:00:00\n",
      "day 0 start\n",
      "day 1 start\n",
      "day 2 start\n",
      "day 3 start\n",
      "day 4 start\n",
      "day 5 start\n",
      "day 6 start\n",
      "day 7 start\n",
      "day 8 start\n",
      "day 9 start\n",
      "generating eventlog...\n",
      "================================================================================================\n",
      "Starting experiment:  15\n",
      "2018-07-01 00:00:00\n",
      "day 0 start\n",
      "day 1 start\n",
      "day 2 start\n",
      "day 3 start\n",
      "day 4 start\n",
      "day 5 start\n",
      "day 6 start\n",
      "day 7 start\n",
      "day 8 start\n",
      "day 9 start\n",
      "generating eventlog...\n",
      "================================================================================================\n",
      "Starting experiment:  16\n",
      "2018-07-01 00:00:00\n",
      "day 0 start\n",
      "day 1 start\n",
      "day 2 start\n",
      "day 3 start\n",
      "day 4 start\n",
      "day 5 start\n",
      "day 6 start\n",
      "day 7 start\n",
      "day 8 start\n",
      "day 9 start\n",
      "generating eventlog...\n",
      "================================================================================================\n",
      "Starting experiment:  17\n",
      "2018-07-01 00:00:00\n",
      "day 0 start\n",
      "day 1 start\n",
      "day 2 start\n",
      "day 3 start\n",
      "day 4 start\n",
      "day 5 start\n",
      "day 6 start\n",
      "day 7 start\n",
      "day 8 start\n",
      "day 9 start\n",
      "generating eventlog...\n",
      "================================================================================================\n",
      "Starting experiment:  18\n",
      "2018-07-01 00:00:00\n",
      "day 0 start\n",
      "day 1 start\n",
      "day 2 start\n",
      "day 3 start\n",
      "day 4 start\n",
      "day 5 start\n",
      "day 6 start\n",
      "day 7 start\n",
      "day 8 start\n",
      "day 9 start\n",
      "generating eventlog...\n",
      "================================================================================================\n",
      "Starting experiment:  19\n",
      "2018-07-01 00:00:00\n",
      "day 0 start\n",
      "day 1 start\n",
      "day 2 start\n",
      "day 3 start\n",
      "day 4 start\n",
      "day 5 start\n",
      "day 6 start\n",
      "day 7 start\n",
      "day 8 start\n",
      "day 9 start\n",
      "generating eventlog...\n",
      "================================================================================================\n",
      "Starting experiment:  20\n",
      "2018-07-01 00:00:00\n",
      "day 0 start\n",
      "day 1 start\n",
      "day 2 start\n",
      "day 3 start\n",
      "day 4 start\n",
      "day 5 start\n",
      "day 6 start\n",
      "day 7 start\n",
      "day 8 start\n",
      "day 9 start\n",
      "generating eventlog...\n"
     ]
    }
   ],
   "source": [
    "#Loop through all experiments in the initial list\n",
    "for experiment_i in experiment_list:\n",
    "    print(\"================================\"*3)\n",
    "    print(\"Starting experiment: \",experiment_i)\n",
    "        \n",
    "    # Load up the experiments for potential updates:\n",
    "    experiments = pd.read_csv(\"results/experiments.csv\")\n",
    "    experiments.index = experiments.RUN.values\n",
    "    \n",
    "    # Get the number of the experiment\n",
    "    RUN = experiments.RUN[experiment_i]\n",
    "    \n",
    "    # Bypass the experiment if it is already performed\n",
    "    if experiments.Done[experiment_i] == 0:\n",
    "        \n",
    "        #create folder for the results\n",
    "        os.mkdir(\"results/\"+str(RUN))\n",
    "        \n",
    "        ####### Factors ######################\n",
    "        # Convert the factors into the original level values\n",
    "        \n",
    "        F_priority_scheme = experiments[experiments.RUN == experiment_i][\"F_priority_scheme\"].values[0]\n",
    "        F_number_of_agents = int(experiments.F_number_of_agents[RUN])\n",
    "        days = int(experiments.days[RUN])\n",
    "        \n",
    "        \n",
    "        \"\"\" run the simulation \"\"\"\n",
    "        start_time = time.time()\n",
    "        evlog, arrived_cases, Case_DB = Run_simulation(agents=F_number_of_agents, \n",
    "                       P_scheme=F_priority_scheme, \n",
    "                       D=days,\n",
    "                       seed=RUN)# to 01/01 2020\n",
    "        \n",
    "        evlog[\"RUN\"] = RUN\n",
    "        evlog.to_csv(\"results/\"+str(RUN)+\"/\"+str(RUN)+\"_log.csv\",index=False)\n",
    "        \n",
    "        Case_DB[\"RUN\"] = RUN        \n",
    "        Case_DB.to_csv(\"results/\"+str(RUN)+\"/\"+str(RUN)+\"_case_DB.csv\",index=False)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        Time_sec = end_time - start_time\n",
    "        \n",
    "        ####### Results ######################\n",
    "        \n",
    "        \"\"\"\n",
    "        avg_est_NPS\n",
    "        avg_est_throughput_time\n",
    "        avg_est_NPS_priority\n",
    "        min_tracelen\n",
    "        max_tracelen\n",
    "        avg_initial_delay\n",
    "        avg_activity_start_delay\n",
    "        avg_duration_delayed\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\" Calculate metrics on closed cases \"\"\"\n",
    "        \n",
    "        evlog_closed = evlog.loc[evlog[\"case_status\"]==\"closed\"]\n",
    "        \n",
    "        experiments.at[RUN, 'closed_avg_actual_NPS'] = np.mean(evlog_closed[\"actual_NPS\"])\n",
    "        experiments.at[RUN, 'closed_avg_actual_throughput_time'] = np.mean(evlog_closed[\"actual_throughput_time\"])\n",
    "        experiments.at[RUN, 'closed_avg_predicted_NPS'] = np.mean(evlog_closed[\"est_NPS\"])\n",
    "        experiments.at[RUN, 'closed_avg_predicted_throughput_time'] = np.mean(evlog_closed[\"est_throughput_time\"])\n",
    "        experiments.at[RUN, 'closed_avg_predicted_NPS_priority'] = np.mean(evlog_closed[\"est_NPS_priority\"])\n",
    "        \n",
    "        experiments.at[RUN, 'closed_avg_initial_delay'] = np.mean(evlog_closed[\"initial_delay\"])\n",
    "        experiments.at[RUN, 'closed_avg_activity_start_delay'] = np.mean(evlog_closed[\"activity_start_delay\"])\n",
    "        experiments.at[RUN, 'closed_avg_duration_delayed'] = np.mean(evlog_closed[\"duration_delayed\"])\n",
    "        \n",
    "        \n",
    "        \"\"\" Calculate metrics on ALL cases \"\"\"\n",
    "        evlog_all = evlog\n",
    "                \n",
    "        experiments.at[RUN, 'all_avg_actual_NPS'] = np.mean(evlog_all[\"actual_NPS\"])\n",
    "        experiments.at[RUN, 'all_avg_actual_throughput_time'] = np.mean(evlog_all[\"actual_throughput_time\"])\n",
    "        experiments.at[RUN, 'all_avg_predicted_NPS'] = np.mean(evlog_all[\"est_NPS\"])\n",
    "        experiments.at[RUN, 'all_avg_predicted_throughput_time'] = np.mean(evlog_all[\"est_throughput_time\"])\n",
    "        experiments.at[RUN, 'all_avg_predicted_NPS_priority'] = np.mean(evlog_all[\"est_NPS_priority\"])\n",
    "        \n",
    "        experiments.at[RUN, 'all_avg_initial_delay'] = np.mean(evlog_all[\"initial_delay\"])\n",
    "        experiments.at[RUN, 'all_avg_activity_start_delay'] = np.mean(evlog_all[\"activity_start_delay\"])\n",
    "        experiments.at[RUN, 'all_avg_duration_delayed'] = np.mean(evlog_all[\"duration_delayed\"])\n",
    "        \n",
    "        \"\"\" other metrics \"\"\"        \n",
    "        experiments.at[RUN, 'cases_arrived'] = arrived_cases\n",
    "        experiments.at[RUN, 'cases_closed'] = evlog.loc[evlog[\"case_status\"]==\"closed\"]['case_id'].nunique()\n",
    "        experiments.at[RUN, 'case_queued'] = Case_DB.loc[(Case_DB[\"case_queued\"]== True)]['theta_idx'].nunique()                \n",
    "        experiments.at[RUN, 'cases_assigned'] = evlog_all['case_id'].nunique()\n",
    "        \n",
    "        experiments.at[RUN, 'min_tracelen'] = np.min(evlog[\"event_no\"])\n",
    "        experiments.at[RUN, 'max_tracelen'] = np.max(evlog[\"event_no\"])\n",
    "        experiments.at[RUN, 'Simulation_duration_min'] = Time_sec/60\n",
    "        \n",
    "        #flag that experiment is done\n",
    "        experiments.at[RUN, 'Done'] = 1\n",
    "        experiments.to_csv(\"results/experiments.csv\",index=False)\n",
    "        \n",
    "        ######################################\n",
    "    \n",
    "# Store results\n",
    "experiments.to_csv(\"results/experiments.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1367b4b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548aa642",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a6b4ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544a6afb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
